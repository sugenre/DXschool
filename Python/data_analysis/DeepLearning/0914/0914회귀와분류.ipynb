{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQlFnLb1nx6D"
      },
      "outputs": [],
      "source": [
        "# 파이썬 ≥3.5 필수\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# 사이킷런 ≥0.20 필수\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# 공통 모듈 임포트\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
        "np.random.seed(42)\n",
        "\n",
        "# 깔끔한 그래프 출력을 위해\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# 그림을 저장할 위치\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"tensorflow\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"그림 저장:\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWTKH05oq8Cl",
        "outputId": "c560afd0-e01c-41df-854f-193b0ad5cb53"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#입력 차원이 1개인 단순 선형 회귀\n",
        "\n",
        "X = np.arange(1, 6)\n",
        "y = 3 * X + 2\n",
        "\n",
        "#모델 만들기\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1, input_shape=[1])\n",
        "])"
      ],
      "metadata": {
        "id": "u1w4h5NEuaMa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델의 구조 확인\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iR7b9CWou-58",
        "outputId": "110f7b77-7eca-4f82-9d83-c19a7efa1a26"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2 (8.00 Byte)\n",
            "Trainable params: 2 (8.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#컴파일\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error',\n",
        "             metrics=['mean_squared_error', 'mean_absolute_error'])\n",
        "\n",
        "#축약해서 작성\n",
        "model.compile(optimizer='sgd', loss='mse', metrics=['mse', 'mae'])\n",
        "\n",
        "#매개변수를 인스턴스 나 함수 또는 변수로 설정\n",
        "model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.005),\n",
        "              loss = tf.keras.losses.MeanSquaredError(),\n",
        "              metrics = [tf.keras.losses.MeanSquaredError(),\n",
        "                         tf.keras.losses.MeanAbsoluteError()])"
      ],
      "metadata": {
        "id": "SKAN4YfovTrx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련\n",
        "#verbose = 0을 추가하면 훈련 과정의 내용이 출력되지 않습니다.\n",
        "history = model.fit(X, y, epochs=2000)"
      ],
      "metadata": {
        "id": "DVIgasBiD_t9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련 과정에서 발생하는 손실 값 과 평가 지표 시각화\n",
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['mean_squared_error'], label='mean_squared_error')\n",
        "plt.xlim(-1, 200)\n",
        "plt.title(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "8dyNA-vpFU6U",
        "outputId": "c13e6d90-c031-41f9-b982-c6a555fb83dd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss\n",
            "mean_squared_error\n",
            "mean_absolute_error\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#검증\n",
        "model.evaluate(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yo1EoN3dGhvc",
        "outputId": "75d4f74c-b0e5-4ff0-c0d0-893ab623e695"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 120ms/step - loss: 1.4382e-07 - mean_squared_error: 1.4382e-07 - mean_absolute_error: 3.2530e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4381971880084166e-07, 1.4381971880084166e-07, 0.00032529831514693797]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#예측\n",
        "model.predict([10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBb0eWIOG6fq",
        "outputId": "70c17e07-6dee-48ec-e3ed-e9752b45a017"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 77ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[32.001568]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ArwaKoy9IZft"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 화이트 와 레드 와인 이항 분류"
      ],
      "metadata": {
        "id": "QOm2yYFPIZnT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 가져오기"
      ],
      "metadata": {
        "id": "2lKaa_nrIcVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "white = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv', sep=\";\")\n",
        "red = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv', sep=\";\")\n",
        "print(white.head())\n",
        "print(red.head())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHQdNFCyIfUq",
        "outputId": "92149c23-fb07-4924-cc87-11bf1447e7ee"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
            "0            7.0              0.27         0.36  ...       0.45      8.8        6\n",
            "1            6.3              0.30         0.34  ...       0.49      9.5        6\n",
            "2            8.1              0.28         0.40  ...       0.44     10.1        6\n",
            "3            7.2              0.23         0.32  ...       0.40      9.9        6\n",
            "4            7.2              0.23         0.32  ...       0.40      9.9        6\n",
            "\n",
            "[5 rows x 12 columns]\n",
            "   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
            "0            7.4              0.70         0.00  ...       0.56      9.4        5\n",
            "1            7.8              0.88         0.00  ...       0.68      9.8        5\n",
            "2            7.8              0.76         0.04  ...       0.65      9.8        5\n",
            "3           11.2              0.28         0.56  ...       0.58      9.8        6\n",
            "4            7.4              0.70         0.00  ...       0.56      9.4        5\n",
            "\n",
            "[5 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "01rwEwMtKnFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#타겟 만들기\n",
        "red['type'] = 0\n",
        "white['type'] = 1\n",
        "\n",
        "#2개의 데이터를 세로 방향으로 합치기\n",
        "wine = pd.concat([red, white])\n",
        "print(wine.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfOoaBLvKoss",
        "outputId": "b27ffe50-b2a9-4a5e-f636-1d3ae6918181"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       fixed acidity  volatile acidity  ...      quality         type\n",
            "count    6497.000000       6497.000000  ...  6497.000000  6497.000000\n",
            "mean        7.215307          0.339666  ...     5.818378     0.753886\n",
            "std         1.296434          0.164636  ...     0.873255     0.430779\n",
            "min         3.800000          0.080000  ...     3.000000     0.000000\n",
            "25%         6.400000          0.230000  ...     5.000000     1.000000\n",
            "50%         7.000000          0.290000  ...     6.000000     1.000000\n",
            "75%         7.700000          0.400000  ...     6.000000     1.000000\n",
            "max        15.900000          1.580000  ...     9.000000     1.000000\n",
            "\n",
            "[8 rows x 13 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 타겟 분포 확인\n",
        "plt.hist(wine['type'])\n",
        "plt.show()\n",
        "#3배 정도 차이가 나는데 이 정도는 괜찮음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "lq8hX2BiLmPm",
        "outputId": "7212e2c7-e05c-4af6-83dd-29bde33cd57f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 정규화\n",
        "#sklearn 의 MinMaxScaler를 이용한 것 과 동일\n",
        "wine_norm = (wine - wine.min()) / (wine.max() - wine.min())\n",
        "print(wine_norm.head())\n",
        "print(wine_norm.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ck9ouLr2MVDe",
        "outputId": "d28e50bd-562c-4083-f975-10e565c6a672"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   fixed acidity  volatile acidity  citric acid  ...   alcohol   quality  type\n",
            "0       0.297521          0.413333     0.000000  ...  0.202899  0.333333   0.0\n",
            "1       0.330579          0.533333     0.000000  ...  0.260870  0.333333   0.0\n",
            "2       0.330579          0.453333     0.024096  ...  0.260870  0.333333   0.0\n",
            "3       0.611570          0.133333     0.337349  ...  0.260870  0.500000   0.0\n",
            "4       0.297521          0.413333     0.000000  ...  0.202899  0.333333   0.0\n",
            "\n",
            "[5 rows x 13 columns]\n",
            "       fixed acidity  volatile acidity  ...      quality         type\n",
            "count    6497.000000       6497.000000  ...  6497.000000  6497.000000\n",
            "mean        0.282257          0.173111  ...     0.469730     0.753886\n",
            "std         0.107143          0.109758  ...     0.145543     0.430779\n",
            "min         0.000000          0.000000  ...     0.000000     0.000000\n",
            "25%         0.214876          0.100000  ...     0.333333     1.000000\n",
            "50%         0.264463          0.140000  ...     0.500000     1.000000\n",
            "75%         0.322314          0.213333  ...     0.500000     1.000000\n",
            "max         1.000000          1.000000  ...     1.000000     1.000000\n",
            "\n",
            "[8 rows x 13 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터 샘플링\n",
        "wine_shuffle = wine_norm.sample(frac=1) #데이터를 섞어서 리턴 - frac은 데이터의 비율\n",
        "print(wine_shuffle.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCWVrwaDNHgH",
        "outputId": "e913afb2-6844-45cb-8e6e-4ea3952304f9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      fixed acidity  volatile acidity  citric acid  ...   alcohol   quality  type\n",
            "1504       0.264463          0.060000     0.445783  ...  0.608696  0.833333   1.0\n",
            "1419       0.322314          0.373333     0.126506  ...  0.275362  0.333333   0.0\n",
            "3162       0.247934          0.206667     0.204819  ...  0.579710  0.666667   1.0\n",
            "3091       0.206612          0.133333     0.283133  ...  0.217391  0.500000   1.0\n",
            "2433       0.297521          0.180000     0.120482  ...  0.130435  0.500000   1.0\n",
            "\n",
            "[5 rows x 13 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pandas의 DataFrame을 numpy 배열로 변환\n",
        "wine_np = wine_shuffle.to_numpy()\n",
        "print(wine_np[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKZ2eyZbNqkc",
        "outputId": "a487d774-81e3-4b44-a787-006f411ff57f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.26446281 0.06       0.44578313 0.18711656 0.05980066 0.07986111\n",
            "  0.2764977  0.13668787 0.41860465 0.08988764 0.60869565 0.83333333\n",
            "  1.        ]\n",
            " [0.32231405 0.37333333 0.12650602 0.02453988 0.11295681 0.10763889\n",
            "  0.29262673 0.16367843 0.42635659 0.12921348 0.27536232 0.33333333\n",
            "  0.        ]\n",
            " [0.24793388 0.20666667 0.20481928 0.10429448 0.01827243 0.12847222\n",
            "  0.29262673 0.09658762 0.35658915 0.12359551 0.57971014 0.66666667\n",
            "  1.        ]\n",
            " [0.20661157 0.13333333 0.28313253 0.16257669 0.05149502 0.20833333\n",
            "  0.4078341  0.1698477  0.31007752 0.16292135 0.2173913  0.5\n",
            "  1.        ]\n",
            " [0.29752066 0.18       0.12048193 0.20398773 0.07475083 0.21527778\n",
            "  0.51382488 0.22691344 0.30232558 0.15730337 0.13043478 0.5\n",
            "  1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련에 사용할 데이터로 생성\n",
        "train_idx = int(len(wine_np) * 0.8)\n",
        "\n",
        "#train_idx 기준으로 행 단위로 분할해서 train 과 test로 분할하고\n",
        "#맨 마지막 열을 기준으로 열 단위로 분할해서 feature 와 target으로 분리\n",
        "train_X, train_Y = wine_np[:train_idx, :-1], wine_np[:train_idx:, -1]\n",
        "test_X, test_Y = wine_np[train_idx:, :-1], wine_np[train_idx:,-1]\n",
        "\n",
        "#레드 와 화이트로 분류할 것이라서 타겟을 원핫 인코딩 수행\n",
        "train_Y = tf.keras.utils.to_categorical(train_Y, num_classes=2)\n",
        "test_Y = tf.keras.utils.to_categorical(test_Y, num_classes=2)\n",
        "print(train_X.shape, test_X.shape)\n",
        "print(train_Y.shape, test_Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XISjDwFVPF0b",
        "outputId": "710ae83b-faa6-477b-de0b-da218d5da398"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5197, 12) (1300, 12)\n",
            "(5197, 2) (1300, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#분류 모델\n",
        "#이항 분류이고 피처의 개수가 12개입니다.\n",
        "#첫번째 입력 층의 input_shape는 무조건 (12, )\n",
        "#맨 마지막 출력 층의 units은 클래스 개수이므로 2 그리고 다항 분류이므로 activation은 softmax\n",
        "#중간 층들의 units는 마음대로 설정 가능하지만 activation은 존재하는 이름을 사용해야 합니다.\n",
        "model = tf.keras.Sequential(\n",
        "    [tf.keras.layers.Dense(units=256, activation='relu', input_shape=(12, )),\n",
        "     tf.keras.layers.Dense(units=128, activation='relu'),\n",
        "     tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "     tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "     tf.keras.layers.Dense(units=16, activation='relu'),\n",
        "     tf.keras.layers.Dense(units=2, activation='softmax')]\n",
        ")\n",
        "#최적화 함수는 Adam이고 학습률은 0.03\n",
        "#손실 함수는 카테고리 크로스 엔트로피\n",
        "#평가 지표는 정확도\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.03),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#구조 확인\n",
        "model.summary()\n",
        "\n",
        "#훈련\n",
        "history = model.fit(train_X, train_Y, epochs=25)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWGwmQg3VZj0",
        "outputId": "aba6b791-6d1e-487c-fdb6-790d337ba8b8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_15 (Dense)            (None, 256)               3328      \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 47122 (184.07 KB)\n",
            "Trainable params: 47122 (184.07 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "163/163 [==============================] - 1s 2ms/step - loss: 0.1579 - accuracy: 0.9359\n",
            "Epoch 2/25\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0449 - accuracy: 0.9873\n",
            "Epoch 3/25\n",
            "163/163 [==============================] - 0s 1ms/step - loss: 0.0377 - accuracy: 0.9894\n",
            "Epoch 4/25\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.9913\n",
            "Epoch 5/25\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.9906\n",
            "Epoch 6/25\n",
            "163/163 [==============================] - 0s 1ms/step - loss: 0.0284 - accuracy: 0.9937\n",
            "Epoch 7/25\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.9931\n",
            "Epoch 8/25\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.9937\n",
            "Epoch 9/25\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9931\n",
            "Epoch 10/25\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.9940\n",
            "Epoch 11/25\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 0.9950\n",
            "Epoch 12/25\n",
            "163/163 [==============================] - 0s 1ms/step - loss: 0.0258 - accuracy: 0.9944\n",
            "Epoch 13/25\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 0.9946\n",
            "Epoch 14/25\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.9956\n",
            "Epoch 15/25\n",
            "163/163 [==============================] - 0s 1ms/step - loss: 0.0246 - accuracy: 0.9940\n",
            "Epoch 16/25\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0327 - accuracy: 0.9911\n",
            "Epoch 17/25\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.9956\n",
            "Epoch 18/25\n",
            "163/163 [==============================] - 0s 1ms/step - loss: 0.0212 - accuracy: 0.9946\n",
            "Epoch 19/25\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 0.9963\n",
            "Epoch 20/25\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 0.9958\n",
            "Epoch 21/25\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.9954\n",
            "Epoch 22/25\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0176 - accuracy: 0.9958\n",
            "Epoch 23/25\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 0.9954\n",
            "Epoch 24/25\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0182 - accuracy: 0.9965\n",
            "Epoch 25/25\n",
            "163/163 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 0.9960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7qjH5LcUc3he"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련\n",
        "#validation_split을 설정하면 그 비율만큼을 검증 데이터로 사용해서 검증을 수행\n",
        "#batch_size는 데이터를 분할해서 학습을 수행\n",
        "history = model.fit(train_X, train_Y, epochs=25, validation_split=0.25,\n",
        "                    batch_size=64)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjNXfjUWcscU",
        "outputId": "af9b9f8e-b307-44f3-b600-8bec9e2f75d2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9985 - val_loss: 0.0171 - val_accuracy: 0.9969\n",
            "Epoch 2/25\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.0180 - val_accuracy: 0.9962\n",
            "Epoch 3/25\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.0184 - val_accuracy: 0.9954\n",
            "Epoch 4/25\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.0178 - val_accuracy: 0.9969\n",
            "Epoch 5/25\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9987 - val_loss: 0.0172 - val_accuracy: 0.9954\n",
            "Epoch 6/25\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9990 - val_loss: 0.0231 - val_accuracy: 0.9962\n",
            "Epoch 7/25\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9987 - val_loss: 0.0164 - val_accuracy: 0.9969\n",
            "Epoch 8/25\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.0178 - val_accuracy: 0.9962\n",
            "Epoch 9/25\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.0194 - val_accuracy: 0.9954\n",
            "Epoch 10/25\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.0349 - val_accuracy: 0.9938\n",
            "Epoch 11/25\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9972 - val_loss: 0.0196 - val_accuracy: 0.9962\n",
            "Epoch 12/25\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.0220 - val_accuracy: 0.9962\n",
            "Epoch 13/25\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0072 - accuracy: 0.9985 - val_loss: 0.0180 - val_accuracy: 0.9954\n",
            "Epoch 14/25\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 0.0244 - val_accuracy: 0.9962\n",
            "Epoch 15/25\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.0226 - val_accuracy: 0.9962\n",
            "Epoch 16/25\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0257 - val_accuracy: 0.9962\n",
            "Epoch 17/25\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.0206 - val_accuracy: 0.9962\n",
            "Epoch 18/25\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.0179 - val_accuracy: 0.9962\n",
            "Epoch 19/25\n",
            "61/61 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.0163 - val_accuracy: 0.9962\n",
            "Epoch 20/25\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0227 - val_accuracy: 0.9962\n",
            "Epoch 21/25\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.0216 - val_accuracy: 0.9962\n",
            "Epoch 22/25\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.0170 - val_accuracy: 0.9969\n",
            "Epoch 23/25\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.0216 - val_accuracy: 0.9962\n",
            "Epoch 24/25\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 0.0350 - val_accuracy: 0.9962\n",
            "Epoch 25/25\n",
            "61/61 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 0.9933 - val_loss: 0.0380 - val_accuracy: 0.9969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#평가\n",
        "model.evaluate(test_X, test_Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K54rQfDZeRl7",
        "outputId": "1ada4b98-3ae5-46d4-efd8-349288300754"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 0s 1ms/step - loss: 0.0496 - accuracy: 0.9938\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04959750175476074, 0.9938461780548096]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H2mMXxeFjCQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 품질을 3가지로 나누어서 분류"
      ],
      "metadata": {
        "id": "22eNww0-jCZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(wine['quality'].describe())\n",
        "print(wine['quality'].value_counts())\n",
        "#3~5를 0, 6을 1 7~9 를 2로 그룹화"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thqKTlpDjG9U",
        "outputId": "7c0f8927-d832-4d32-9066-d53b13c48cd0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count    6497.000000\n",
            "mean        5.818378\n",
            "std         0.873255\n",
            "min         3.000000\n",
            "25%         5.000000\n",
            "50%         6.000000\n",
            "75%         6.000000\n",
            "max         9.000000\n",
            "Name: quality, dtype: float64\n",
            "6    2836\n",
            "5    2138\n",
            "7    1079\n",
            "4     216\n",
            "8     193\n",
            "3      30\n",
            "9       5\n",
            "Name: quality, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#타겟 생성\n",
        "wine.loc[wine['quality'] <= 5, 'new_quality'] = 0\n",
        "wine.loc[wine['quality'] == 6, 'new_quality'] = 1\n",
        "wine.loc[wine['quality'] >= 7, 'new_quality'] = 2\n",
        "print(wine.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr_ZQjabjv8B",
        "outputId": "54bc0f38-7e5f-40cb-f033-4402143602ce"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   fixed acidity  volatile acidity  citric acid  ...  quality  type  new_quality\n",
            "0            7.4              0.70         0.00  ...        5     0          0.0\n",
            "1            7.8              0.88         0.00  ...        5     0          0.0\n",
            "2            7.8              0.76         0.04  ...        5     0          0.0\n",
            "3           11.2              0.28         0.56  ...        6     0          1.0\n",
            "4            7.4              0.70         0.00  ...        5     0          0.0\n",
            "\n",
            "[5 rows x 14 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#피처 정규화\n",
        "#del wine['quality']\n",
        "del wine['type']\n",
        "wine_backup = wine.copy() #복제본 생성\n",
        "\n",
        "#타겟을 제외한 부분을 정규화\n",
        "wine_norm = (wine - wine.min()) / (wine.max() - wine.min())\n",
        "wine_norm['new_quality'] = wine_backup['new_quality']\n",
        "print(wine_norm.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yJ_A4sXkwFi",
        "outputId": "5fb7deeb-b5d8-4bdb-822c-a15d0379dfbd"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   fixed acidity  volatile acidity  ...   alcohol  new_quality\n",
            "0       0.297521          0.413333  ...  0.202899          0.0\n",
            "1       0.330579          0.533333  ...  0.260870          0.0\n",
            "2       0.330579          0.453333  ...  0.260870          0.0\n",
            "3       0.611570          0.133333  ...  0.260870          1.0\n",
            "4       0.297521          0.413333  ...  0.202899          0.0\n",
            "\n",
            "[5 rows x 12 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련 데이터 와 테스트 데이터를 분할\n",
        "wine_shuffle = wine_norm.sample(frac=1)\n",
        "wine_np = wine_shuffle.to_numpy()\n",
        "train_idx = int(len(wine_np) * 0.8)\n",
        "train_X, train_Y = wine_np[:train_idx, :-1], wine_np[:train_idx, -1]\n",
        "test_X, test_Y = wine_np[train_idx:, :-1], wine_np[train_idx:, -1]\n",
        "#타겟을 원핫인코딩 하기\n",
        "train_Y = tf.keras.utils.to_categorical(train_Y, num_classes=3)\n",
        "test_Y = tf.keras.utils.to_categorical(test_Y, num_classes=3)"
      ],
      "metadata": {
        "id": "7S4xJJsxlmZ0"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 만들기\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=2048, activation='relu', input_shape = (11, )),\n",
        "    tf.keras.layers.Dense(units=1024, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=512, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=32, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=16, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=8, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=3, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr = 0.005),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(train_X, train_Y, epochs=200, batch_size=32, validation_split=0.25)\n",
        "model.evaluate(test_X, test_Y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yShMBrkmm3zZ",
        "outputId": "f7c921b1-027f-4069-e461-b2d61f9cc867"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "122/122 [==============================] - 6s 33ms/step - loss: 0.9864 - accuracy: 0.4935 - val_loss: 0.9303 - val_accuracy: 0.5200\n",
            "Epoch 2/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.9382 - accuracy: 0.5422 - val_loss: 0.9074 - val_accuracy: 0.5738\n",
            "Epoch 3/200\n",
            "122/122 [==============================] - 4s 35ms/step - loss: 0.9751 - accuracy: 0.5089 - val_loss: 0.9093 - val_accuracy: 0.5769\n",
            "Epoch 4/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.9227 - accuracy: 0.5291 - val_loss: 0.8896 - val_accuracy: 0.5269\n",
            "Epoch 5/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.8868 - accuracy: 0.5607 - val_loss: 0.8926 - val_accuracy: 0.5508\n",
            "Epoch 6/200\n",
            "122/122 [==============================] - 4s 34ms/step - loss: 0.8748 - accuracy: 0.5684 - val_loss: 0.8597 - val_accuracy: 0.5854\n",
            "Epoch 7/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.8788 - accuracy: 0.5591 - val_loss: 0.9094 - val_accuracy: 0.5615\n",
            "Epoch 8/200\n",
            "122/122 [==============================] - 4s 29ms/step - loss: 0.8700 - accuracy: 0.5766 - val_loss: 0.8408 - val_accuracy: 0.5800\n",
            "Epoch 9/200\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.8566 - accuracy: 0.5784 - val_loss: 0.8443 - val_accuracy: 0.5731\n",
            "Epoch 10/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.8573 - accuracy: 0.5787 - val_loss: 0.8331 - val_accuracy: 0.5854\n",
            "Epoch 11/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.8482 - accuracy: 0.5799 - val_loss: 0.8563 - val_accuracy: 0.5723\n",
            "Epoch 12/200\n",
            "122/122 [==============================] - 4s 35ms/step - loss: 0.8528 - accuracy: 0.5815 - val_loss: 0.8424 - val_accuracy: 0.5908\n",
            "Epoch 13/200\n",
            "122/122 [==============================] - 3s 28ms/step - loss: 0.8457 - accuracy: 0.5840 - val_loss: 0.8250 - val_accuracy: 0.5846\n",
            "Epoch 14/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.8459 - accuracy: 0.5810 - val_loss: 0.8407 - val_accuracy: 0.6015\n",
            "Epoch 15/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.8511 - accuracy: 0.5830 - val_loss: 0.8342 - val_accuracy: 0.5846\n",
            "Epoch 16/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.8430 - accuracy: 0.5851 - val_loss: 0.8299 - val_accuracy: 0.5931\n",
            "Epoch 17/200\n",
            "122/122 [==============================] - 3s 29ms/step - loss: 0.8400 - accuracy: 0.5920 - val_loss: 0.8301 - val_accuracy: 0.5931\n",
            "Epoch 18/200\n",
            "122/122 [==============================] - 4s 34ms/step - loss: 0.8265 - accuracy: 0.5897 - val_loss: 0.8155 - val_accuracy: 0.6054\n",
            "Epoch 19/200\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.8397 - accuracy: 0.5923 - val_loss: 0.8574 - val_accuracy: 0.5815\n",
            "Epoch 20/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.8241 - accuracy: 0.5976 - val_loss: 0.8464 - val_accuracy: 0.5923\n",
            "Epoch 21/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.8338 - accuracy: 0.5856 - val_loss: 0.8284 - val_accuracy: 0.5954\n",
            "Epoch 22/200\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.8184 - accuracy: 0.5938 - val_loss: 0.8635 - val_accuracy: 0.5900\n",
            "Epoch 23/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.8170 - accuracy: 0.5923 - val_loss: 0.8323 - val_accuracy: 0.5900\n",
            "Epoch 24/200\n",
            "122/122 [==============================] - 4s 34ms/step - loss: 0.8164 - accuracy: 0.5989 - val_loss: 0.8069 - val_accuracy: 0.6131\n",
            "Epoch 25/200\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.8053 - accuracy: 0.6061 - val_loss: 0.8170 - val_accuracy: 0.6100\n",
            "Epoch 26/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.8168 - accuracy: 0.6025 - val_loss: 0.7977 - val_accuracy: 0.6146\n",
            "Epoch 27/200\n",
            "122/122 [==============================] - 4s 34ms/step - loss: 0.8121 - accuracy: 0.5994 - val_loss: 0.7962 - val_accuracy: 0.6123\n",
            "Epoch 28/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.7974 - accuracy: 0.6061 - val_loss: 0.8112 - val_accuracy: 0.6185\n",
            "Epoch 29/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.8056 - accuracy: 0.5997 - val_loss: 0.8282 - val_accuracy: 0.5931\n",
            "Epoch 30/200\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.8028 - accuracy: 0.6092 - val_loss: 0.8051 - val_accuracy: 0.6185\n",
            "Epoch 31/200\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.7906 - accuracy: 0.6087 - val_loss: 0.8310 - val_accuracy: 0.5969\n",
            "Epoch 32/200\n",
            "122/122 [==============================] - 4s 29ms/step - loss: 0.8000 - accuracy: 0.6028 - val_loss: 0.8043 - val_accuracy: 0.6062\n",
            "Epoch 33/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.7867 - accuracy: 0.6159 - val_loss: 0.8135 - val_accuracy: 0.6131\n",
            "Epoch 34/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.7894 - accuracy: 0.6118 - val_loss: 0.8041 - val_accuracy: 0.6023\n",
            "Epoch 35/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.7854 - accuracy: 0.6184 - val_loss: 0.8229 - val_accuracy: 0.6085\n",
            "Epoch 36/200\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.7855 - accuracy: 0.6123 - val_loss: 0.8043 - val_accuracy: 0.6208\n",
            "Epoch 37/200\n",
            "122/122 [==============================] - 4s 34ms/step - loss: 0.7990 - accuracy: 0.6035 - val_loss: 0.8192 - val_accuracy: 0.6192\n",
            "Epoch 38/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.7856 - accuracy: 0.6182 - val_loss: 0.8072 - val_accuracy: 0.6177\n",
            "Epoch 39/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.7803 - accuracy: 0.6146 - val_loss: 0.8050 - val_accuracy: 0.6238\n",
            "Epoch 40/200\n",
            "122/122 [==============================] - 4s 35ms/step - loss: 0.7760 - accuracy: 0.6184 - val_loss: 0.8044 - val_accuracy: 0.6069\n",
            "Epoch 41/200\n",
            "122/122 [==============================] - 4s 29ms/step - loss: 0.7780 - accuracy: 0.6238 - val_loss: 0.7994 - val_accuracy: 0.6200\n",
            "Epoch 42/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.7711 - accuracy: 0.6200 - val_loss: 0.8120 - val_accuracy: 0.6077\n",
            "Epoch 43/200\n",
            "122/122 [==============================] - 4s 35ms/step - loss: 0.7713 - accuracy: 0.6192 - val_loss: 0.8367 - val_accuracy: 0.6123\n",
            "Epoch 44/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.7654 - accuracy: 0.6287 - val_loss: 0.8205 - val_accuracy: 0.6123\n",
            "Epoch 45/200\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.7609 - accuracy: 0.6302 - val_loss: 0.8120 - val_accuracy: 0.6238\n",
            "Epoch 46/200\n",
            "122/122 [==============================] - 4s 34ms/step - loss: 0.7612 - accuracy: 0.6264 - val_loss: 0.8120 - val_accuracy: 0.6223\n",
            "Epoch 47/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.7596 - accuracy: 0.6289 - val_loss: 0.8089 - val_accuracy: 0.6254\n",
            "Epoch 48/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.7506 - accuracy: 0.6333 - val_loss: 0.8083 - val_accuracy: 0.6269\n",
            "Epoch 49/200\n",
            "122/122 [==============================] - 4s 35ms/step - loss: 0.7448 - accuracy: 0.6336 - val_loss: 0.8354 - val_accuracy: 0.6123\n",
            "Epoch 50/200\n",
            "122/122 [==============================] - 4s 29ms/step - loss: 0.7464 - accuracy: 0.6338 - val_loss: 0.8185 - val_accuracy: 0.6131\n",
            "Epoch 51/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.7511 - accuracy: 0.6338 - val_loss: 0.8148 - val_accuracy: 0.6177\n",
            "Epoch 52/200\n",
            "122/122 [==============================] - 4s 35ms/step - loss: 0.7393 - accuracy: 0.6387 - val_loss: 0.8342 - val_accuracy: 0.6231\n",
            "Epoch 53/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.7348 - accuracy: 0.6323 - val_loss: 0.8561 - val_accuracy: 0.6162\n",
            "Epoch 54/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.7389 - accuracy: 0.6459 - val_loss: 0.8101 - val_accuracy: 0.6123\n",
            "Epoch 55/200\n",
            "122/122 [==============================] - 4s 34ms/step - loss: 0.7394 - accuracy: 0.6377 - val_loss: 0.8041 - val_accuracy: 0.6146\n",
            "Epoch 56/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.7279 - accuracy: 0.6397 - val_loss: 0.8013 - val_accuracy: 0.6177\n",
            "Epoch 57/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.7217 - accuracy: 0.6477 - val_loss: 0.8180 - val_accuracy: 0.6215\n",
            "Epoch 58/200\n",
            "122/122 [==============================] - 4s 37ms/step - loss: 0.7207 - accuracy: 0.6502 - val_loss: 0.8512 - val_accuracy: 0.6100\n",
            "Epoch 59/200\n",
            "122/122 [==============================] - 4s 29ms/step - loss: 0.7222 - accuracy: 0.6531 - val_loss: 0.8145 - val_accuracy: 0.6131\n",
            "Epoch 60/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.7107 - accuracy: 0.6585 - val_loss: 0.8204 - val_accuracy: 0.6054\n",
            "Epoch 61/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.7066 - accuracy: 0.6662 - val_loss: 0.9018 - val_accuracy: 0.6162\n",
            "Epoch 62/200\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.7066 - accuracy: 0.6536 - val_loss: 0.8466 - val_accuracy: 0.6038\n",
            "Epoch 63/200\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.6916 - accuracy: 0.6654 - val_loss: 0.8852 - val_accuracy: 0.6138\n",
            "Epoch 64/200\n",
            "122/122 [==============================] - 4s 35ms/step - loss: 0.6932 - accuracy: 0.6633 - val_loss: 0.8740 - val_accuracy: 0.6100\n",
            "Epoch 65/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.6781 - accuracy: 0.6713 - val_loss: 0.8803 - val_accuracy: 0.6208\n",
            "Epoch 66/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.6978 - accuracy: 0.6626 - val_loss: 0.8637 - val_accuracy: 0.6077\n",
            "Epoch 67/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.6926 - accuracy: 0.6687 - val_loss: 0.8698 - val_accuracy: 0.6215\n",
            "Epoch 68/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.6755 - accuracy: 0.6785 - val_loss: 0.8525 - val_accuracy: 0.6185\n",
            "Epoch 69/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.6675 - accuracy: 0.6746 - val_loss: 0.8740 - val_accuracy: 0.6131\n",
            "Epoch 70/200\n",
            "122/122 [==============================] - 4s 34ms/step - loss: 0.6630 - accuracy: 0.6821 - val_loss: 0.8475 - val_accuracy: 0.5969\n",
            "Epoch 71/200\n",
            "122/122 [==============================] - 4s 29ms/step - loss: 0.6635 - accuracy: 0.6859 - val_loss: 0.8912 - val_accuracy: 0.6262\n",
            "Epoch 72/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.6623 - accuracy: 0.6859 - val_loss: 0.8867 - val_accuracy: 0.6231\n",
            "Epoch 73/200\n",
            "122/122 [==============================] - 4s 35ms/step - loss: 0.6508 - accuracy: 0.6918 - val_loss: 0.9461 - val_accuracy: 0.6231\n",
            "Epoch 74/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.6410 - accuracy: 0.6903 - val_loss: 0.8905 - val_accuracy: 0.6231\n",
            "Epoch 75/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.6344 - accuracy: 0.7018 - val_loss: 0.9327 - val_accuracy: 0.6300\n",
            "Epoch 76/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.6272 - accuracy: 0.6939 - val_loss: 1.0420 - val_accuracy: 0.6062\n",
            "Epoch 77/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.6454 - accuracy: 0.6867 - val_loss: 0.8706 - val_accuracy: 0.6146\n",
            "Epoch 78/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.6441 - accuracy: 0.7075 - val_loss: 0.9466 - val_accuracy: 0.6238\n",
            "Epoch 79/200\n",
            "122/122 [==============================] - 4s 35ms/step - loss: 0.6161 - accuracy: 0.7113 - val_loss: 0.9368 - val_accuracy: 0.6269\n",
            "Epoch 80/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.6103 - accuracy: 0.7098 - val_loss: 0.9684 - val_accuracy: 0.6138\n",
            "Epoch 81/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.6179 - accuracy: 0.7095 - val_loss: 0.9909 - val_accuracy: 0.6169\n",
            "Epoch 82/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.6179 - accuracy: 0.7108 - val_loss: 0.9876 - val_accuracy: 0.6292\n",
            "Epoch 83/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5951 - accuracy: 0.7188 - val_loss: 1.0513 - val_accuracy: 0.6200\n",
            "Epoch 84/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.6328 - accuracy: 0.7041 - val_loss: 0.9642 - val_accuracy: 0.6077\n",
            "Epoch 85/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.6380 - accuracy: 0.7021 - val_loss: 0.9097 - val_accuracy: 0.6200\n",
            "Epoch 86/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5894 - accuracy: 0.7206 - val_loss: 1.0004 - val_accuracy: 0.6238\n",
            "Epoch 87/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.5843 - accuracy: 0.7300 - val_loss: 1.0251 - val_accuracy: 0.6377\n",
            "Epoch 88/200\n",
            "122/122 [==============================] - 4s 35ms/step - loss: 0.5697 - accuracy: 0.7416 - val_loss: 1.0126 - val_accuracy: 0.6208\n",
            "Epoch 89/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5644 - accuracy: 0.7403 - val_loss: 0.9656 - val_accuracy: 0.6231\n",
            "Epoch 90/200\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.5541 - accuracy: 0.7460 - val_loss: 1.0215 - val_accuracy: 0.6123\n",
            "Epoch 91/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.6180 - accuracy: 0.7154 - val_loss: 0.9882 - val_accuracy: 0.6162\n",
            "Epoch 92/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5608 - accuracy: 0.7501 - val_loss: 1.0149 - val_accuracy: 0.6269\n",
            "Epoch 93/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5935 - accuracy: 0.7313 - val_loss: 1.0298 - val_accuracy: 0.6185\n",
            "Epoch 94/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.5563 - accuracy: 0.7419 - val_loss: 1.1336 - val_accuracy: 0.6123\n",
            "Epoch 95/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5061 - accuracy: 0.7773 - val_loss: 1.1993 - val_accuracy: 0.6208\n",
            "Epoch 96/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.5058 - accuracy: 0.7649 - val_loss: 1.2713 - val_accuracy: 0.6162\n",
            "Epoch 97/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.4922 - accuracy: 0.7780 - val_loss: 1.2515 - val_accuracy: 0.6338\n",
            "Epoch 98/200\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.5333 - accuracy: 0.7667 - val_loss: 1.0549 - val_accuracy: 0.6446\n",
            "Epoch 99/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4918 - accuracy: 0.7827 - val_loss: 1.1671 - val_accuracy: 0.6031\n",
            "Epoch 100/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.5126 - accuracy: 0.7734 - val_loss: 1.1399 - val_accuracy: 0.6431\n",
            "Epoch 101/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4928 - accuracy: 0.7850 - val_loss: 1.0830 - val_accuracy: 0.6162\n",
            "Epoch 102/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4885 - accuracy: 0.7832 - val_loss: 1.1231 - val_accuracy: 0.6154\n",
            "Epoch 103/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.4493 - accuracy: 0.8070 - val_loss: 1.3214 - val_accuracy: 0.6200\n",
            "Epoch 104/200\n",
            "122/122 [==============================] - 4s 29ms/step - loss: 0.4307 - accuracy: 0.8140 - val_loss: 1.3900 - val_accuracy: 0.6292\n",
            "Epoch 105/200\n",
            "122/122 [==============================] - 4s 29ms/step - loss: 0.4284 - accuracy: 0.8109 - val_loss: 1.3243 - val_accuracy: 0.6169\n",
            "Epoch 106/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.4426 - accuracy: 0.8078 - val_loss: 1.3662 - val_accuracy: 0.6123\n",
            "Epoch 107/200\n",
            "122/122 [==============================] - 4s 29ms/step - loss: 0.4275 - accuracy: 0.8129 - val_loss: 1.2764 - val_accuracy: 0.6523\n",
            "Epoch 108/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.4298 - accuracy: 0.8168 - val_loss: 1.3857 - val_accuracy: 0.6146\n",
            "Epoch 109/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.4138 - accuracy: 0.8281 - val_loss: 1.4027 - val_accuracy: 0.6423\n",
            "Epoch 110/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.3715 - accuracy: 0.8435 - val_loss: 1.3545 - val_accuracy: 0.6400\n",
            "Epoch 111/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.3823 - accuracy: 0.8386 - val_loss: 1.4282 - val_accuracy: 0.6223\n",
            "Epoch 112/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.4077 - accuracy: 0.8276 - val_loss: 1.5950 - val_accuracy: 0.6038\n",
            "Epoch 113/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.4007 - accuracy: 0.8317 - val_loss: 1.2556 - val_accuracy: 0.6454\n",
            "Epoch 114/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.3534 - accuracy: 0.8530 - val_loss: 1.6002 - val_accuracy: 0.6277\n",
            "Epoch 115/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.3472 - accuracy: 0.8537 - val_loss: 1.4592 - val_accuracy: 0.6462\n",
            "Epoch 116/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.3430 - accuracy: 0.8584 - val_loss: 1.4088 - val_accuracy: 0.6415\n",
            "Epoch 117/200\n",
            "122/122 [==============================] - 4s 29ms/step - loss: 0.3715 - accuracy: 0.8471 - val_loss: 1.2149 - val_accuracy: 0.6408\n",
            "Epoch 118/200\n",
            "122/122 [==============================] - 4s 35ms/step - loss: 0.3505 - accuracy: 0.8489 - val_loss: 1.4490 - val_accuracy: 0.6323\n",
            "Epoch 119/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.3145 - accuracy: 0.8740 - val_loss: 1.7985 - val_accuracy: 0.6469\n",
            "Epoch 120/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.3492 - accuracy: 0.8499 - val_loss: 1.3655 - val_accuracy: 0.6269\n",
            "Epoch 121/200\n",
            "122/122 [==============================] - 4s 35ms/step - loss: 0.3447 - accuracy: 0.8499 - val_loss: 1.7749 - val_accuracy: 0.6531\n",
            "Epoch 122/200\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.3302 - accuracy: 0.8609 - val_loss: 1.6867 - val_accuracy: 0.6554\n",
            "Epoch 123/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.2861 - accuracy: 0.8850 - val_loss: 1.3941 - val_accuracy: 0.6485\n",
            "Epoch 124/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.2780 - accuracy: 0.8871 - val_loss: 1.7882 - val_accuracy: 0.6462\n",
            "Epoch 125/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.2764 - accuracy: 0.8850 - val_loss: 1.7876 - val_accuracy: 0.6354\n",
            "Epoch 126/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.2847 - accuracy: 0.8820 - val_loss: 2.0035 - val_accuracy: 0.6377\n",
            "Epoch 127/200\n",
            "122/122 [==============================] - 4s 35ms/step - loss: 0.2699 - accuracy: 0.8861 - val_loss: 1.7669 - val_accuracy: 0.6438\n",
            "Epoch 128/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.2830 - accuracy: 0.8866 - val_loss: 1.5758 - val_accuracy: 0.6377\n",
            "Epoch 129/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.2608 - accuracy: 0.8866 - val_loss: 1.8264 - val_accuracy: 0.6531\n",
            "Epoch 130/200\n",
            "122/122 [==============================] - 4s 35ms/step - loss: 0.2769 - accuracy: 0.8873 - val_loss: 1.5685 - val_accuracy: 0.6369\n",
            "Epoch 131/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.2751 - accuracy: 0.8886 - val_loss: 1.5718 - val_accuracy: 0.6562\n",
            "Epoch 132/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.2414 - accuracy: 0.9012 - val_loss: 1.7704 - val_accuracy: 0.6769\n",
            "Epoch 133/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.2248 - accuracy: 0.9117 - val_loss: 1.6097 - val_accuracy: 0.6362\n",
            "Epoch 134/200\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.2993 - accuracy: 0.8891 - val_loss: 1.9158 - val_accuracy: 0.6585\n",
            "Epoch 135/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.2152 - accuracy: 0.9099 - val_loss: 1.9537 - val_accuracy: 0.6646\n",
            "Epoch 136/200\n",
            "122/122 [==============================] - 4s 35ms/step - loss: 0.2322 - accuracy: 0.9092 - val_loss: 2.1541 - val_accuracy: 0.6423\n",
            "Epoch 137/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.2126 - accuracy: 0.9089 - val_loss: 2.3545 - val_accuracy: 0.6469\n",
            "Epoch 138/200\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.2297 - accuracy: 0.9120 - val_loss: 1.6036 - val_accuracy: 0.6562\n",
            "Epoch 139/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.1898 - accuracy: 0.9240 - val_loss: 2.1165 - val_accuracy: 0.6577\n",
            "Epoch 140/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.2213 - accuracy: 0.9140 - val_loss: 1.7797 - val_accuracy: 0.6408\n",
            "Epoch 141/200\n",
            "122/122 [==============================] - 4s 29ms/step - loss: 0.2154 - accuracy: 0.9210 - val_loss: 1.7321 - val_accuracy: 0.6477\n",
            "Epoch 142/200\n",
            "122/122 [==============================] - 4s 35ms/step - loss: 0.1939 - accuracy: 0.9192 - val_loss: 2.2383 - val_accuracy: 0.6385\n",
            "Epoch 143/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.1958 - accuracy: 0.9184 - val_loss: 2.2976 - val_accuracy: 0.6554\n",
            "Epoch 144/200\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.1718 - accuracy: 0.9323 - val_loss: 2.1192 - val_accuracy: 0.6577\n",
            "Epoch 145/200\n",
            "122/122 [==============================] - 5s 37ms/step - loss: 0.2362 - accuracy: 0.9104 - val_loss: 2.0923 - val_accuracy: 0.6569\n",
            "Epoch 146/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.1794 - accuracy: 0.9261 - val_loss: 2.0612 - val_accuracy: 0.6746\n",
            "Epoch 147/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.1737 - accuracy: 0.9310 - val_loss: 2.1225 - val_accuracy: 0.6515\n",
            "Epoch 148/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.2165 - accuracy: 0.9215 - val_loss: 1.6567 - val_accuracy: 0.6600\n",
            "Epoch 149/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.1815 - accuracy: 0.9251 - val_loss: 1.9861 - val_accuracy: 0.6592\n",
            "Epoch 150/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.1594 - accuracy: 0.9369 - val_loss: 2.2786 - val_accuracy: 0.6715\n",
            "Epoch 151/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.1617 - accuracy: 0.9407 - val_loss: 2.0656 - val_accuracy: 0.6600\n",
            "Epoch 152/200\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.1406 - accuracy: 0.9461 - val_loss: 2.4660 - val_accuracy: 0.6677\n",
            "Epoch 153/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.1564 - accuracy: 0.9389 - val_loss: 2.2947 - val_accuracy: 0.6615\n",
            "Epoch 154/200\n",
            "122/122 [==============================] - 4s 35ms/step - loss: 0.1671 - accuracy: 0.9376 - val_loss: 2.2782 - val_accuracy: 0.6415\n",
            "Epoch 155/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.1616 - accuracy: 0.9389 - val_loss: 2.0691 - val_accuracy: 0.6585\n",
            "Epoch 156/200\n",
            "122/122 [==============================] - 4s 29ms/step - loss: 0.1862 - accuracy: 0.9289 - val_loss: 2.6512 - val_accuracy: 0.6454\n",
            "Epoch 157/200\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.1409 - accuracy: 0.9487 - val_loss: 2.5000 - val_accuracy: 0.6546\n",
            "Epoch 158/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.1842 - accuracy: 0.9292 - val_loss: 2.5293 - val_accuracy: 0.6323\n",
            "Epoch 159/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.1583 - accuracy: 0.9371 - val_loss: 2.2124 - val_accuracy: 0.6515\n",
            "Epoch 160/200\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.1399 - accuracy: 0.9461 - val_loss: 2.2406 - val_accuracy: 0.6523\n",
            "Epoch 161/200\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.1290 - accuracy: 0.9515 - val_loss: 2.1706 - val_accuracy: 0.6515\n",
            "Epoch 162/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.1303 - accuracy: 0.9479 - val_loss: 2.2259 - val_accuracy: 0.6692\n",
            "Epoch 163/200\n",
            "122/122 [==============================] - 4s 29ms/step - loss: 0.1343 - accuracy: 0.9518 - val_loss: 2.2499 - val_accuracy: 0.6554\n",
            "Epoch 164/200\n",
            "122/122 [==============================] - 4s 34ms/step - loss: 0.1309 - accuracy: 0.9500 - val_loss: 2.6061 - val_accuracy: 0.6662\n",
            "Epoch 165/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.1225 - accuracy: 0.9525 - val_loss: 2.3411 - val_accuracy: 0.6546\n",
            "Epoch 166/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.1371 - accuracy: 0.9502 - val_loss: 2.1345 - val_accuracy: 0.6392\n",
            "Epoch 167/200\n",
            "122/122 [==============================] - 4s 35ms/step - loss: 0.1217 - accuracy: 0.9561 - val_loss: 2.1062 - val_accuracy: 0.6454\n",
            "Epoch 168/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.1195 - accuracy: 0.9546 - val_loss: 2.4346 - val_accuracy: 0.6462\n",
            "Epoch 169/200\n",
            "122/122 [==============================] - 4s 29ms/step - loss: 0.1602 - accuracy: 0.9453 - val_loss: 2.3354 - val_accuracy: 0.6292\n",
            "Epoch 170/200\n",
            "122/122 [==============================] - 4s 34ms/step - loss: 0.1315 - accuracy: 0.9551 - val_loss: 2.4481 - val_accuracy: 0.6562\n",
            "Epoch 171/200\n",
            "122/122 [==============================] - 4s 29ms/step - loss: 0.1573 - accuracy: 0.9456 - val_loss: 2.0506 - val_accuracy: 0.6669\n",
            "Epoch 172/200\n",
            "122/122 [==============================] - 4s 29ms/step - loss: 0.1100 - accuracy: 0.9623 - val_loss: 2.2721 - val_accuracy: 0.6631\n",
            "Epoch 173/200\n",
            "122/122 [==============================] - 4s 34ms/step - loss: 0.1324 - accuracy: 0.9502 - val_loss: 2.2135 - val_accuracy: 0.6600\n",
            "Epoch 174/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.0830 - accuracy: 0.9679 - val_loss: 2.5317 - val_accuracy: 0.6638\n",
            "Epoch 175/200\n",
            "122/122 [==============================] - 4s 29ms/step - loss: 0.1081 - accuracy: 0.9582 - val_loss: 2.4338 - val_accuracy: 0.6562\n",
            "Epoch 176/200\n",
            "122/122 [==============================] - 4s 35ms/step - loss: 0.1338 - accuracy: 0.9548 - val_loss: 2.1931 - val_accuracy: 0.6623\n",
            "Epoch 177/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.1096 - accuracy: 0.9602 - val_loss: 2.9722 - val_accuracy: 0.6546\n",
            "Epoch 178/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.1175 - accuracy: 0.9577 - val_loss: 2.2372 - val_accuracy: 0.6492\n",
            "Epoch 179/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.1412 - accuracy: 0.9520 - val_loss: 1.7808 - val_accuracy: 0.6377\n",
            "Epoch 180/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.1038 - accuracy: 0.9592 - val_loss: 2.5160 - val_accuracy: 0.6592\n",
            "Epoch 181/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.1047 - accuracy: 0.9628 - val_loss: 2.5429 - val_accuracy: 0.6600\n",
            "Epoch 182/200\n",
            "122/122 [==============================] - 4s 35ms/step - loss: 0.1112 - accuracy: 0.9648 - val_loss: 2.4607 - val_accuracy: 0.6654\n",
            "Epoch 183/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.0981 - accuracy: 0.9648 - val_loss: 2.7038 - val_accuracy: 0.6623\n",
            "Epoch 184/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.1222 - accuracy: 0.9548 - val_loss: 1.8403 - val_accuracy: 0.6669\n",
            "Epoch 185/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.0958 - accuracy: 0.9682 - val_loss: 2.2806 - val_accuracy: 0.6777\n",
            "Epoch 186/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.1286 - accuracy: 0.9538 - val_loss: 2.5796 - val_accuracy: 0.6623\n",
            "Epoch 187/200\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.1285 - accuracy: 0.9523 - val_loss: 2.3655 - val_accuracy: 0.6569\n",
            "Epoch 188/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.1433 - accuracy: 0.9536 - val_loss: 1.8949 - val_accuracy: 0.6623\n",
            "Epoch 189/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0885 - accuracy: 0.9682 - val_loss: 2.6877 - val_accuracy: 0.6646\n",
            "Epoch 190/200\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.1073 - accuracy: 0.9618 - val_loss: 2.2978 - val_accuracy: 0.6538\n",
            "Epoch 191/200\n",
            "122/122 [==============================] - 5s 37ms/step - loss: 0.0978 - accuracy: 0.9654 - val_loss: 2.2003 - val_accuracy: 0.6577\n",
            "Epoch 192/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0944 - accuracy: 0.9618 - val_loss: 2.7740 - val_accuracy: 0.6700\n",
            "Epoch 193/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.0849 - accuracy: 0.9690 - val_loss: 2.2857 - val_accuracy: 0.6638\n",
            "Epoch 194/200\n",
            "122/122 [==============================] - 4s 36ms/step - loss: 0.1027 - accuracy: 0.9636 - val_loss: 2.3743 - val_accuracy: 0.6569\n",
            "Epoch 195/200\n",
            "122/122 [==============================] - 4s 31ms/step - loss: 0.1040 - accuracy: 0.9613 - val_loss: 2.5800 - val_accuracy: 0.6569\n",
            "Epoch 196/200\n",
            "122/122 [==============================] - 4s 29ms/step - loss: 0.0996 - accuracy: 0.9674 - val_loss: 2.0242 - val_accuracy: 0.6715\n",
            "Epoch 197/200\n",
            "122/122 [==============================] - 4s 33ms/step - loss: 0.1100 - accuracy: 0.9615 - val_loss: 2.6024 - val_accuracy: 0.6592\n",
            "Epoch 198/200\n",
            "122/122 [==============================] - 4s 30ms/step - loss: 0.0864 - accuracy: 0.9687 - val_loss: 2.2176 - val_accuracy: 0.6615\n",
            "Epoch 199/200\n",
            "122/122 [==============================] - 4s 32ms/step - loss: 0.0830 - accuracy: 0.9707 - val_loss: 2.0213 - val_accuracy: 0.6754\n",
            "Epoch 200/200\n",
            "122/122 [==============================] - 5s 37ms/step - loss: 0.1189 - accuracy: 0.9602 - val_loss: 1.9367 - val_accuracy: 0.6500\n",
            "41/41 [==============================] - 0s 6ms/step - loss: 1.9829 - accuracy: 0.6731\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.9828886985778809, 0.6730769276618958]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hcje6ICBjFaf"
      }
    }
  ]
}